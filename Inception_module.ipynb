{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception module.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "F7-uv3YBmal9"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chlin1/TimeSeries/blob/master/Inception_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ysjU_vu6jFvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [Inception module](http://marubon-ds.blogspot.com/2018/06/how-to-write-inception-module.html?m=1)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OlFJF6vujDVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6002dd03-8712-49b8-f974-5ff8b97a3c5b"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((60000, 28, 28, 1))[0:2000]\n",
        "y_train = to_categorical(y_train, 10)[0:2000]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CIMpt2vlkBjq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The naive_inception\n",
        "The naive_inception() expresses naive version of Inception module. Three types of kernels are used and concatenated."
      ]
    },
    {
      "metadata": {
        "id": "MNu7Zor4kJnh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Input, Conv2D, Flatten, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "def naive_inception(inputs):\n",
        "\n",
        "    towerOne = Conv2D(6, (1,1), activation='relu', border_mode='same')(inputs)\n",
        "    towerTwo = Conv2D(6, (3,3), activation='relu', border_mode='same')(inputs)\n",
        "    towerThree = Conv2D(6, (5,5), activation='relu', border_mode='same')(inputs)\n",
        "    x = concatenate([towerOne, towerTwo, towerThree], axis=3)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCskTFyakS2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inception module with dimension reduction"
      ]
    },
    {
      "metadata": {
        "id": "i-skU6a5kO8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dimension_reduction_inception(inputs):\n",
        "    tower_one = MaxPooling2D((3,3), strides=(1,1), padding='same')(inputs)\n",
        "    tower_one = Conv2D(6, (1,1), activation='relu', border_mode='same')(tower_one)\n",
        "\n",
        "    tower_two = Conv2D(6, (1,1), activation='relu', border_mode='same')(inputs)\n",
        "    tower_two = Conv2D(6, (3,3), activation='relu', border_mode='same')(tower_two)\n",
        "\n",
        "    tower_three = Conv2D(6, (1,1), activation='relu', border_mode='same')(inputs)\n",
        "    tower_three = Conv2D(6, (5,5), activation='relu', border_mode='same')(tower_three)\n",
        "    x = concatenate([towerOne, towerTwo, towerThree], axis=3)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7-uv3YBmal9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST with the naive_inception"
      ]
    },
    {
      "metadata": {
        "id": "BpHwcQuTmb8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2146
        },
        "outputId": "1f80ce89-1983-470c-809c-e1a33f94b118"
      },
      "cell_type": "code",
      "source": [
        "def naive_model(x_train):\n",
        "\n",
        "    inputs = Input(x_train.shape[1:])\n",
        "\n",
        "    x = naive_inception(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(input=inputs, output=predictions)\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                 optimizer=keras.optimizers.SGD(lr=0.0001),\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "modelA = naive_model(x_train)\n",
        "modelA.fit(x_train, y_train, epochs=50, shuffle=True,  validation_split=0.1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (1, 1), activation=\"relu\", padding=\"same\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (5, 5), activation=\"relu\", padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "1800/1800 [==============================] - 3s 1ms/step - loss: 9.7523 - acc: 0.3617 - val_loss: 7.7163 - val_acc: 0.4850\n",
            "Epoch 2/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 7.5235 - acc: 0.5061 - val_loss: 6.6882 - val_acc: 0.5600\n",
            "Epoch 3/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 6.5948 - acc: 0.5650 - val_loss: 5.7328 - val_acc: 0.6100\n",
            "Epoch 4/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 5.8731 - acc: 0.6083 - val_loss: 6.7353 - val_acc: 0.5250\n",
            "Epoch 5/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 5.3580 - acc: 0.6400 - val_loss: 4.7710 - val_acc: 0.6550\n",
            "Epoch 6/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 4.6331 - acc: 0.6872 - val_loss: 4.0941 - val_acc: 0.7050\n",
            "Epoch 7/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 4.2060 - acc: 0.7139 - val_loss: 3.4604 - val_acc: 0.7550\n",
            "Epoch 8/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 3.7764 - acc: 0.7450 - val_loss: 2.5488 - val_acc: 0.7850\n",
            "Epoch 9/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.8760 - acc: 0.7850 - val_loss: 2.1704 - val_acc: 0.8250\n",
            "Epoch 10/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.2118 - acc: 0.8389 - val_loss: 1.8199 - val_acc: 0.8500\n",
            "Epoch 11/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.1165 - acc: 0.8472 - val_loss: 2.5689 - val_acc: 0.7850\n",
            "Epoch 12/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.0101 - acc: 0.8578 - val_loss: 1.7595 - val_acc: 0.8700\n",
            "Epoch 13/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.8695 - acc: 0.8733 - val_loss: 1.6662 - val_acc: 0.8600\n",
            "Epoch 14/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.8140 - acc: 0.8800 - val_loss: 1.7074 - val_acc: 0.8750\n",
            "Epoch 15/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7830 - acc: 0.8839 - val_loss: 1.7209 - val_acc: 0.8700\n",
            "Epoch 16/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7597 - acc: 0.8894 - val_loss: 1.7425 - val_acc: 0.8650\n",
            "Epoch 17/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7630 - acc: 0.8883 - val_loss: 1.7218 - val_acc: 0.8700\n",
            "Epoch 18/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7495 - acc: 0.8911 - val_loss: 1.7097 - val_acc: 0.8650\n",
            "Epoch 19/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7478 - acc: 0.8911 - val_loss: 1.7406 - val_acc: 0.8700\n",
            "Epoch 20/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7464 - acc: 0.8917 - val_loss: 1.7398 - val_acc: 0.8700\n",
            "Epoch 21/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7394 - val_acc: 0.8700\n",
            "Epoch 22/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7394 - val_acc: 0.8700\n",
            "Epoch 23/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7393 - val_acc: 0.8700\n",
            "Epoch 24/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7393 - val_acc: 0.8700\n",
            "Epoch 25/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7394 - val_acc: 0.8700\n",
            "Epoch 26/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7395 - val_acc: 0.8700\n",
            "Epoch 27/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7463 - acc: 0.8917 - val_loss: 1.7395 - val_acc: 0.8700\n",
            "Epoch 28/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7402 - val_acc: 0.8700\n",
            "Epoch 29/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7401 - val_acc: 0.8700\n",
            "Epoch 30/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7401 - val_acc: 0.8700\n",
            "Epoch 31/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7402 - val_acc: 0.8700\n",
            "Epoch 32/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7402 - val_acc: 0.8700\n",
            "Epoch 33/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7402 - val_acc: 0.8750\n",
            "Epoch 34/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7401 - val_acc: 0.8750\n",
            "Epoch 35/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7400 - val_acc: 0.8750\n",
            "Epoch 36/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7400 - val_acc: 0.8750\n",
            "Epoch 37/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7399 - val_acc: 0.8750\n",
            "Epoch 38/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7398 - val_acc: 0.8750\n",
            "Epoch 39/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7397 - val_acc: 0.8750\n",
            "Epoch 40/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7397 - val_acc: 0.8750\n",
            "Epoch 41/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7396 - val_acc: 0.8750\n",
            "Epoch 42/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7392 - val_acc: 0.8750\n",
            "Epoch 43/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7393 - val_acc: 0.8750\n",
            "Epoch 44/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7392 - val_acc: 0.8750\n",
            "Epoch 45/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7392 - val_acc: 0.8750\n",
            "Epoch 46/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7392 - val_acc: 0.8750\n",
            "Epoch 47/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7392 - val_acc: 0.8750\n",
            "Epoch 48/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7387 - val_acc: 0.8750\n",
            "Epoch 49/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7387 - val_acc: 0.8750\n",
            "Epoch 50/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.7462 - acc: 0.8917 - val_loss: 1.7387 - val_acc: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff98def5f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "79cVqv3Cm3Eq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8f5542fc-c3bf-41b8-f4b7-20425568d7fa"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "def show_history(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'test_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "show_history(modelA.history)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngBBCmJQkACGEMKn/D0ynDazKZ01kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "a9NV9eAfm_PC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST with Inception module with dimension reduction"
      ]
    },
    {
      "metadata": {
        "id": "T8Z7e3qrm6up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2037
        },
        "outputId": "5e13e1ff-e4c0-435e-ee1e-374434d3eec3"
      },
      "cell_type": "code",
      "source": [
        "def dimension_reduction_model(x_train):\n",
        "\n",
        "    inputs = Input(x_train.shape[1:])\n",
        "\n",
        "    x = dimension_reduction_inception(inputs)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(input=inputs, output=predictions)\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                 optimizer=keras.optimizers.SGD(lr=0.0001),\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "modelB = naive_model(x_train)\n",
        "modelB.fit(x_train, y_train, epochs=50, shuffle=True,  validation_split=0.1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (1, 1), activation=\"relu\", padding=\"same\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (5, 5), activation=\"relu\", padding=\"same\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1800 samples, validate on 200 samples\n",
            "Epoch 1/50\n",
            "1800/1800 [==============================] - 3s 1ms/step - loss: 10.6672 - acc: 0.3106 - val_loss: 7.8847 - val_acc: 0.4900\n",
            "Epoch 2/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 6.1247 - acc: 0.5817 - val_loss: 5.6498 - val_acc: 0.6200\n",
            "Epoch 3/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 4.6057 - acc: 0.6817 - val_loss: 5.9498 - val_acc: 0.5950\n",
            "Epoch 4/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 3.6929 - acc: 0.7339 - val_loss: 3.9952 - val_acc: 0.7250\n",
            "Epoch 5/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.5967 - acc: 0.8111 - val_loss: 2.6788 - val_acc: 0.7950\n",
            "Epoch 6/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 2.1172 - acc: 0.8428 - val_loss: 2.5586 - val_acc: 0.8150\n",
            "Epoch 7/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.8404 - acc: 0.8650 - val_loss: 2.9808 - val_acc: 0.7700\n",
            "Epoch 8/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.6006 - acc: 0.8772 - val_loss: 1.9701 - val_acc: 0.8400\n",
            "Epoch 9/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.3692 - acc: 0.9011 - val_loss: 3.1639 - val_acc: 0.7500\n",
            "Epoch 10/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.3031 - acc: 0.9033 - val_loss: 4.4316 - val_acc: 0.6650\n",
            "Epoch 11/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 1.4295 - acc: 0.8967 - val_loss: 1.7810 - val_acc: 0.8500\n",
            "Epoch 12/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.9649 - acc: 0.9256 - val_loss: 1.8340 - val_acc: 0.8600\n",
            "Epoch 13/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.9268 - acc: 0.9306 - val_loss: 1.4453 - val_acc: 0.8800\n",
            "Epoch 14/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.8546 - acc: 0.9389 - val_loss: 1.3598 - val_acc: 0.9050\n",
            "Epoch 15/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.8794 - acc: 0.9350 - val_loss: 1.6866 - val_acc: 0.8750\n",
            "Epoch 16/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.8518 - acc: 0.9339 - val_loss: 1.5876 - val_acc: 0.8800\n",
            "Epoch 17/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.7838 - acc: 0.9444 - val_loss: 1.5310 - val_acc: 0.8750\n",
            "Epoch 18/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.7969 - acc: 0.9417 - val_loss: 1.2519 - val_acc: 0.8950\n",
            "Epoch 19/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6695 - acc: 0.9494 - val_loss: 1.3758 - val_acc: 0.8850\n",
            "Epoch 20/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6423 - acc: 0.9561 - val_loss: 1.3507 - val_acc: 0.9000\n",
            "Epoch 21/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6121 - acc: 0.9583 - val_loss: 1.4568 - val_acc: 0.8850\n",
            "Epoch 22/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.6579 - acc: 0.9533 - val_loss: 1.2972 - val_acc: 0.8850\n",
            "Epoch 23/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5486 - acc: 0.9606 - val_loss: 1.3847 - val_acc: 0.9000\n",
            "Epoch 24/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5254 - acc: 0.9656 - val_loss: 1.3145 - val_acc: 0.8900\n",
            "Epoch 25/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5143 - acc: 0.9672 - val_loss: 1.3612 - val_acc: 0.8950\n",
            "Epoch 26/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5199 - acc: 0.9667 - val_loss: 1.3352 - val_acc: 0.9000\n",
            "Epoch 27/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3360 - val_acc: 0.9000\n",
            "Epoch 28/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3363 - val_acc: 0.9000\n",
            "Epoch 29/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3364 - val_acc: 0.9000\n",
            "Epoch 30/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3364 - val_acc: 0.9000\n",
            "Epoch 31/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3364 - val_acc: 0.9000\n",
            "Epoch 32/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3363 - val_acc: 0.9000\n",
            "Epoch 33/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3361 - val_acc: 0.9000\n",
            "Epoch 34/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3360 - val_acc: 0.9000\n",
            "Epoch 35/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3359 - val_acc: 0.9000\n",
            "Epoch 36/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3357 - val_acc: 0.9000\n",
            "Epoch 37/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3354 - val_acc: 0.9000\n",
            "Epoch 38/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3353 - val_acc: 0.9000\n",
            "Epoch 39/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3351 - val_acc: 0.9000\n",
            "Epoch 40/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3350 - val_acc: 0.9000\n",
            "Epoch 41/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3348 - val_acc: 0.9000\n",
            "Epoch 42/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3348 - val_acc: 0.9000\n",
            "Epoch 43/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3347 - val_acc: 0.9000\n",
            "Epoch 44/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3346 - val_acc: 0.9000\n",
            "Epoch 45/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3345 - val_acc: 0.9000\n",
            "Epoch 46/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3344 - val_acc: 0.9000\n",
            "Epoch 47/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3343 - val_acc: 0.9000\n",
            "Epoch 48/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3342 - val_acc: 0.9000\n",
            "Epoch 49/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3342 - val_acc: 0.9000\n",
            "Epoch 50/50\n",
            "1800/1800 [==============================] - 2s 1ms/step - loss: 0.5104 - acc: 0.9683 - val_loss: 1.3341 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff986a09ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "RxaDUk_nnHyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f8836f92-eee4-403f-d65f-17d60fbe941a"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "def show_history(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'test_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "show_history(modelA.history)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngBBCmJQkACGEMKn/D0ynDazKZ01kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "spQ1HN5jt5-O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inception module"
      ]
    },
    {
      "metadata": {
        "id": "9B_bBpn3t7Je",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Input\n",
        "\n",
        "input_img = Input(shape=(256, 256, 3))\n",
        "\n",
        "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
        "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
        "\n",
        "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
        "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
        "\n",
        "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
        "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfkch96Kr-p_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## cifar10"
      ]
    },
    {
      "metadata": {
        "id": "lsZioXKjsOye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each image is represented as 32x32 pixels each for red, blue and green channels. Each pixel has a value between 0255. Next, we normalize the values to 01."
      ]
    },
    {
      "metadata": {
        "id": "cLY48R7YnLgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2355
        },
        "outputId": "9a43f3fc-94af-4821-ce85-6b6c6e770499"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6357724f15a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/datasets/cifar10.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cifar-10-batches-py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnum_train_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [Errno 110] Connection timed out"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UhxPNf5DsPg-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to best model the classification model, we convert y_test and y_train to one hot representations in the form of a binary matrix."
      ]
    },
    {
      "metadata": {
        "id": "tpY7hoOtsSwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t9W8bbiNsrFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The latest Keras functional API allows us to define complex models. In order to create a model, let us first define an input_img tensor for a 32x32 image with 3 channels(RGB)."
      ]
    },
    {
      "metadata": {
        "id": "DDDU7iUJsa-f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "input_img = Input(shape = (32, 32, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jmm8uqV4sjDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we feed the input tensor to each of the 1x1, 3x3, 5x5 filters in the inception module\n",
        "\n",
        "The padding is kept same so that the output shape of the Conv2D operation is same as the input shape. So, the final output of each filter of tower_1, tower_2 and tower_3 is same. Thus we can easily concatenate these filters to form the output of our inception module."
      ]
    },
    {
      "metadata": {
        "id": "nBkxJoojskN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)\n",
        "tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)\n",
        "tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRowmig6tU1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Flatten, Dense\n",
        "output = Flatten()(output)\n",
        "out    = Dense(10, activation='softmax')(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1sv1LgltYK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "model = Model(inputs = input_img, outputs = out)\n",
        "# print model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EekEZ7TTtb41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "epochs = 25\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTTri2Vbtg2-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "import os\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(os.path.join(os.getcwd(), 'model.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUvM1vkFti3g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "El4ng1Y2tmOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}